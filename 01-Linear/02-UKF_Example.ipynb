{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Imports ##\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import time as timeit\n",
    "import datetime\n",
    "import sys,os\n",
    "\n",
    "## Kalman Filter Imports ##\n",
    "from filterpy.kalman import UnscentedKalmanFilter\n",
    "from filterpy.kalman import MerweScaledSigmaPoints\n",
    "from filterpy.kalman import unscented_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscented Kalman Filter\n",
    "In this file, I develop an unscented Kalman filter (UKF) solution to the identification of a single-degree-of-freedom oscillator (SDOF), in which the nonlinear switch state is turned OFF, essentially developing a linear, shear-frame SDOF system. The nonlinear stiffness contribution is turned off for this part of the example, as part of the switch state for this system. \n",
    "\n",
    "The UKF incorporates a small set of hyperparameters used to adjust the deterministic selection of the small set of sigma points used in the filtering approximation. For this example, these parameters are selected according to the \"standard\" values suggested by Wan and Van Der Merwe<sup>1</sup>, as listed below.\n",
    "    \n",
    "1. $\\alpha = 0.001$, where $\\alpha$ determines the spread of the sigma points about the mean of the latent state approximation. \n",
    "2. $\\kappa = 0$, where $\\kappa$ is a secondary scaling parameter on the sigma points. \n",
    "3. $\\beta = 2$, where $\\beta$ incorporates knowledge of the distribution on the latent states and $\\beta = 2$ is the optimal representation for Gaussian distributions.  \n",
    "\n",
    "Additional hyperparameters in an experimental scenario include the process noise covariance $Q$ and the process noise covariance $R$. However, these terms are assumed known for this problem. It should also be noted that where the EKF uses the a smoothed approximation of the dynamical model for the system, the UKF can operate on the non-smooth model directly. \n",
    "\n",
    "This example runs 50 inference trials using varied prior information on the parameters, simulating different assertions an experimentalist might make in a practical identification scenario. Outputs from this model include:\n",
    "1. The mean and standard deviation of the state and log(parameters) over the inference period. \n",
    "2. The mean of the state and parameters over the inference period. \n",
    "3. The mode of the state and parameters over the inference period. \n",
    "4. The computational model response built from the inferred parameters with respect to the input signal used for inference.\n",
    "5. The runtime for each inference trial. \n",
    "\n",
    "The UKF implementation expressed herein is drawn from the python library FilterPy<sup>2</sup>. Some small modifications were made to adapt the library to this problem, and are shown in detail in the code below. \n",
    "\n",
    "__Developed by__: Alana Lund (Purdue University) \\\n",
    "__Last Updated__: 22 Sept. 2021 \\\n",
    "__License__: AGPL-3.0\n",
    "\n",
    "### References\n",
    "<sup>1</sup> E. Wan and R. Van Der Merwe. The unscented Kalman filter for nonlinear estimation. _Proceedings of IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium._ (2000). pp 153-158. \n",
    "\n",
    "<sup>2</sup> R. Labbe, FilterPy v1.4.5, (2021). [https://github.com/rlabbe/filterpy](https://github.com/rlabbe/filterpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Names\n",
    "inFile = '../04-Data/Linear/inferenceInput'\n",
    "outFile = '../04-Data/Linear/outputUKF'\n",
    "\n",
    "infData = np.load(inFile + '.npz')\n",
    "\n",
    "dt = infData['dt']                 # time step [sec]\n",
    "time = infData['time']             # time history [sec]\n",
    "inpAcc = infData['inpAcc']         # observations on input acceleration [m/sec^2]\n",
    "states = infData['statesPNoise']   # states (for post-inference validation) [m,m/sec]\n",
    "respAcc = infData['accPMNoise']    # observations on response acceleration [m/sec^2]\n",
    "Q = infData['Qfactor']             # process noise contributions, independent std. dev. per state [m,m/sec]\n",
    "R = infData['Rfactor']             # measurement noise contribution [m/sec^2]\n",
    "m = infData['m']                   # mass [kg]\n",
    "ics = infData['ics']               # true initial conditions of the system [m, m/sec]\n",
    "par = infData['par']               # true parameters of the system [xi (-), wn (rad/sec)] \n",
    "\n",
    "### Lay Out Problem Dimensionality ###\n",
    "nInf = 4                     # Number of inferred variables [-]\n",
    "nState = states.shape[0]     # Number of states [-]\n",
    "nPar = nInf - nState         # Number of parameters [-]\n",
    "samps = len(time)            # Number of system measurements [-]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transition and Emission Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt, exc=None):\n",
    "    \"\"\"\n",
    "    State transition model for a SDOF oscillator with a Bouc-Wen switch \n",
    "    state, given that alpha = 0, and therefore the Bouc-Wen component is \n",
    "    switched off.\n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    dt = sampling rate [sec]\n",
    "    exc = input excitation at current time step [m/sec^2]\n",
    "    \"\"\"\n",
    "    if exc is None:\n",
    "        exc = np.zeros(x[1].shape)\n",
    "      \n",
    "    par = np.exp(x[2:])         \n",
    "    x1dot = x[0] + dt*x[1]\n",
    "    x2dot = x[1] + dt*(-exc - (2*par[0]*par[1])*x[1] - np.square(par[1])*x[0])\n",
    "\n",
    "    return np.concatenate((np.stack((x1dot, x2dot), axis=0)\n",
    "                           , x[2:]), axis=0)\n",
    "\n",
    "def hx(x):\n",
    "    \"\"\"\n",
    "    Measurement model for a SDOF oscillator with a Bouc-Wen switch \n",
    "    state, given that alpha = 0, and therefore the Bouc-Wen component is \n",
    "    switched off.\n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    \"\"\"  \n",
    "    par = np.exp(x[2:])\n",
    "    resp = -(2*par[0]*par[1])*x[1] - np.square(par[1])*x[0]\n",
    "    return np.eye(1)*resp # Dimensionality matching for FilterPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_measUT(sigmas, Wm, Wc, noise_cov=None,\n",
    "                        mean_fn=None, residual_fn=None):\n",
    "    \"\"\"\n",
    "    This function is an optional input to the \"update\" step of the UKF\n",
    "    algorithm in FilterPy, which allows for a user-generated calculation\n",
    "    of the unscented transform, given a set of sigma points and their \n",
    "    weights. I define this function to enable the computation of the \n",
    "    unscented transform in the case where there is only one vector of \n",
    "    system observations. \n",
    "    \n",
    "    This function works in conjunction with the UnscentedKalmanFilter \n",
    "    class, and follows the terminology therein.\n",
    "    \n",
    "    sigmas = Nx(2N+1) matrix containing the sigma points to be evaluated\n",
    "    Wm = vector of weights on the sigma points for the computation  \n",
    "         of the mean\n",
    "    Wc = vector of weights on the sigma points for the computation\n",
    "         of the covariance\n",
    "    noise_cov = noise matrix added to the final computational covariance\n",
    "                matrix\n",
    "    mean_fn = Function that computes the mean of the provided sigma points\n",
    "              and weights. Useful for state variables containin nonlinear \n",
    "              values which cannot be summed.\n",
    "    residual_fn = Function that computes the residual (difference) between \n",
    "                  x and y. Useful for state variable that do not support \n",
    "                  subtraction. \n",
    "    \"\"\"\n",
    "    sigmas = sigmas[:,:,0] # Dimensionality matching for FilterPy\n",
    "    kmax, n = sigmas.shape # Determine number of states (kmax) and\n",
    "                           # number of sigma points (n)\n",
    "\n",
    "    ## Approximate the Gaussian Mean ##\n",
    "    try:\n",
    "        if mean_fn is None:\n",
    "            x = np.dot(Wm, sigmas)    # dot = \\Sum^n_1 (W[k]*Xi[k])\n",
    "        else:\n",
    "            x = mean_fn(sigmas, Wm)\n",
    "    except:\n",
    "        print(sigmas)\n",
    "        raise\n",
    "\n",
    "    ## Approximate the Gaussian Covariance ##\n",
    "    # The approximate covariance is the sum of the \n",
    "    # outer product of the residuals times the weights\n",
    "    if residual_fn is np.subtract or residual_fn is None:\n",
    "        # Fast Way\n",
    "        y = sigmas - x[np.newaxis, :]\n",
    "        P = np.dot(y.T, np.dot(np.diag(Wc), y))\n",
    "    else:\n",
    "        # Slow Way\n",
    "        P = np.zeros((n, n))\n",
    "        for k in range(kmax):\n",
    "            y = residual_fn(sigmas[k], x)\n",
    "            P += Wc[k] * np.outer(y, y)\n",
    "\n",
    "    if noise_cov is not None:\n",
    "        P += noise_cov\n",
    "\n",
    "    return (x, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run UKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0897\n",
      "\twn = 3.0069\n",
      "\n",
      "Iteration 1\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0846\n",
      "\twn = 3.0021\n",
      "\n",
      "Iteration 2\n",
      "Computation Time = 1.30 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0739\n",
      "\twn = 2.9952\n",
      "\n",
      "Iteration 3\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0510\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 4\n",
      "Computation Time = 1.25 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0486\n",
      "\twn = 2.9922\n",
      "\n",
      "Iteration 5\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0881\n",
      "\twn = 3.0055\n",
      "\n",
      "Iteration 6\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0508\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 7\n",
      "Computation Time = 1.21 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0722\n",
      "\twn = 2.9956\n",
      "\n",
      "Iteration 8\n",
      "Computation Time = 1.25 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0832\n",
      "\twn = 3.0001\n",
      "\n",
      "Iteration 9\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0486\n",
      "\twn = 2.9943\n",
      "\n",
      "Iteration 10\n",
      "Computation Time = 1.29 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0850\n",
      "\twn = 3.0016\n",
      "\n",
      "Iteration 11\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0803\n",
      "\twn = 2.9967\n",
      "\n",
      "Iteration 12\n",
      "Computation Time = 1.18 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0546\n",
      "\twn = 2.9927\n",
      "\n",
      "Iteration 13\n",
      "Computation Time = 1.22 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0499\n",
      "\twn = 2.9928\n",
      "\n",
      "Iteration 14\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0487\n",
      "\twn = 2.9922\n",
      "\n",
      "Iteration 15\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0561\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 16\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0506\n",
      "\twn = 2.9927\n",
      "\n",
      "Iteration 17\n",
      "Computation Time = 1.28 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0649\n",
      "\twn = 2.9921\n",
      "\n",
      "Iteration 18\n",
      "Computation Time = 1.20 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0488\n",
      "\twn = 2.9946\n",
      "\n",
      "Iteration 19\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0911\n",
      "\twn = 3.0082\n",
      "\n",
      "Iteration 20\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0851\n",
      "\twn = 3.0010\n",
      "\n",
      "Iteration 21\n",
      "Computation Time = 1.29 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0786\n",
      "\twn = 2.9964\n",
      "\n",
      "Iteration 22\n",
      "Computation Time = 1.21 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0558\n",
      "\twn = 2.9928\n",
      "\n",
      "Iteration 23\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0800\n",
      "\twn = 2.9975\n",
      "\n",
      "Iteration 24\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0816\n",
      "\twn = 2.9974\n",
      "\n",
      "Iteration 25\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0988\n",
      "\twn = 3.0167\n",
      "\n",
      "Iteration 26\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0485\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 27\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0636\n",
      "\twn = 2.9893\n",
      "\n",
      "Iteration 28\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0845\n",
      "\twn = 3.0012\n",
      "\n",
      "Iteration 29\n",
      "Computation Time = 1.25 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0794\n",
      "\twn = 2.9978\n",
      "\n",
      "Iteration 30\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0734\n",
      "\twn = 2.9959\n",
      "\n",
      "Iteration 31\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0791\n",
      "\twn = 2.9968\n",
      "\n",
      "Iteration 32\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0798\n",
      "\twn = 2.9981\n",
      "\n",
      "Iteration 33\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0665\n",
      "\twn = 2.9897\n",
      "\n",
      "Iteration 34\n",
      "Computation Time = 1.23 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0516\n",
      "\twn = 2.9925\n",
      "\n",
      "Iteration 35\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0831\n",
      "\twn = 3.0012\n",
      "\n",
      "Iteration 36\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0759\n",
      "\twn = 2.9956\n",
      "\n",
      "Iteration 37\n",
      "Computation Time = 1.21 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0490\n",
      "\twn = 2.9930\n",
      "\n",
      "Iteration 38\n",
      "Computation Time = 1.19 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0785\n",
      "\twn = 2.9971\n",
      "\n",
      "Iteration 39\n",
      "Computation Time = 1.22 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0908\n",
      "\twn = 3.0078\n",
      "\n",
      "Iteration 40\n",
      "Computation Time = 1.20 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0486\n",
      "\twn = 2.9925\n",
      "\n",
      "Iteration 41\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0553\n",
      "\twn = 2.9929\n",
      "\n",
      "Iteration 42\n",
      "Computation Time = 1.25 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0630\n",
      "\twn = 2.9940\n",
      "\n",
      "Iteration 43\n",
      "Computation Time = 1.21 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0663\n",
      "\twn = 2.9909\n",
      "\n",
      "Iteration 44\n",
      "Computation Time = 1.29 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0493\n",
      "\twn = 2.9941\n",
      "\n",
      "Iteration 45\n",
      "Computation Time = 1.27 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0519\n",
      "\twn = 2.9919\n",
      "\n",
      "Iteration 46\n",
      "Computation Time = 1.25 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0725\n",
      "\twn = 2.9950\n",
      "\n",
      "Iteration 47\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0491\n",
      "\twn = 2.9932\n",
      "\n",
      "Iteration 48\n",
      "Computation Time = 1.24 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0789\n",
      "\twn = 2.9964\n",
      "\n",
      "Iteration 49\n",
      "Computation Time = 1.26 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0874\n",
      "\twn = 3.0050\n"
     ]
    }
   ],
   "source": [
    "### Load Prior Distributions on the Parameters ###\n",
    "parPriors = np.loadtxt('../04-Data/parameter_priors.txt')\n",
    "\n",
    "### Generate Storage Over Inferred States/Parameters ###\n",
    "muHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mean of the inferred parameters for each inference trial\n",
    "    # over the observation period. This is what the EKF directly\n",
    "    # outputs\n",
    "stdHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # standard deviation of the inferred parameters for each \n",
    "    # inference trial over the observation period. This is \n",
    "    # what the EKF directly outputs\n",
    "meanHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mean of the inferred states and the underlying parameters\n",
    "    # for each inference trial over the observation period. This\n",
    "    # measure transforms the parameters to a lognormal distribution\n",
    "    # such that the statistics on the true parameter values can be\n",
    "    # extracted. \n",
    "modeHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mode of the inferred states and the underlying parameters\n",
    "    # for each inference trial over the observation period. This\n",
    "    # measure transforms the parameters to a lognormal distribution\n",
    "    # such that the statistics on the true parameter values can be\n",
    "    # extracted. \n",
    "modStates = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # Response history of the inferred system given the input\n",
    "    # excitation. Essentially, we're remodeling the behavior of \n",
    "    # the system given our selections on point estimates of the \n",
    "    # parameters from the posterior. \n",
    "runTime = np.zeros((parPriors.shape[0]))\n",
    "    # Computational time for each inference trial. \n",
    "\n",
    "## For Each Inference Trial... ##\n",
    "for j in range(parPriors.shape[0]):\n",
    "    ### Create an Instance of the UKF Class ##\n",
    "    sigPoints = MerweScaledSigmaPoints(nInf, alpha=0.001, beta=2, kappa=0)\n",
    "        # Initialize sigma point generator class\n",
    "    kf = UnscentedKalmanFilter(dim_x=nInf, dim_z=1, dt=dt, \n",
    "                               fx=fx, hx=hx,points=sigPoints)\n",
    "        # Initialize UKF solver class with 8 states (2 dynamic, 2 parameters)\n",
    "    \n",
    "    ### Initialize UKF Priors ###\n",
    "    mu0 = np.concatenate((np.zeros((nState,)), parPriors[j,:4:2]))\n",
    "    P0 = np.diag(np.square(np.concatenate((np.array([0.05, 0.05])\n",
    "                                 ,parPriors[j,1:5:2]))))\n",
    "  \n",
    "    kf.x = mu0    # Prior mean on the states and parameters\n",
    "    kf.P = P0     # Prior covariacne on the states and parameters\n",
    "    kf.Q = np.diag(np.concatenate((np.square(Q), 10**(-15)*np.ones(nPar))))\n",
    "        # Adding a little jitter on the parameter transition density is\n",
    "        # standard practice in the joint state-parameter estimation problem. \n",
    "        # Doing so avoids singularity in the covariance on the transition dynamics\n",
    "    kf.R = R**2\n",
    "\n",
    "    ## Store Initial Values ##\n",
    "    muHist[j,:,0] = kf.x \n",
    "    stdHist[j,:,0] = np.sqrt(np.diag(kf.P))\n",
    "    meanHist[j,:,0] = np.concatenate((kf.x[0:nState], np.exp(kf.x[nState:] \n",
    "                                        + np.square(stdHist[j,nState:,0])/2)))\n",
    "    modeHist[j,:,0] = np.concatenate((kf.x[0:nState], np.exp(kf.x[nState:] \n",
    "                                        - np.square(stdHist[j,nState:,0]))))\n",
    "\n",
    "    ### Run UKF Over Data ###\n",
    "    t0 = timeit.time()\n",
    "    try: \n",
    "        for i in range(1,samps):\n",
    "            ## Predictor ##\n",
    "            kf.predict(exc = inpAcc[i-1])\n",
    "            ## Corrector ##\n",
    "            kf.update(respAcc[i], UT=my_measUT)\n",
    "\n",
    "            ## Store Results ##\n",
    "            muHist[j,:,i] = kf.x\n",
    "            stdHist[j,:,i] = np.sqrt(np.diag(kf.P))\n",
    "            meanHist[j,:,i] = np.concatenate((kf.x[0:nState], \n",
    "                                    np.exp(kf.x[nState:] + np.square(stdHist[j,nState:,i])/2)))\n",
    "            modeHist[j,:,i] = np.concatenate((kf.x[0:nState], np.exp(kf.x[nState:] \n",
    "                                    - np.square(stdHist[j,nState:,i]))))\n",
    "    except:\n",
    "        print('\\nERROR: Numerical Instability')\n",
    "        ## Store Results ##\n",
    "        for i in range(1,samps):\n",
    "            muHist[j,:,i] = np.array([0,0,-0.1054, 2.3])\n",
    "            stdHist[j,:,i] = 0.01*np.ones(4)\n",
    "            meanHist[j,:,i] = np.concatenate((muHist[j,:nState,i], \n",
    "                                    np.exp(muHist[j,nState:,i] + np.square(stdHist[j,nState:,i])/2)))\n",
    "            modeHist[j,:,i] = np.concatenate((muHist[j,:nState,i], np.exp(muHist[j,nState:,i] \n",
    "                                    - np.square(stdHist[j,nState:,i]))))\n",
    "        \n",
    "    ### Rerun Model with Point Estimates (Mode) of Inferred Parameters ###\n",
    "    modStates[j,:,0] = np.concatenate((np.zeros((2,)), np.log(modeHist[j,2:,-1])))\n",
    "    for i in range(1,samps):\n",
    "        modStates[j,:,i] = fx(modStates[j,:,i-1], dt, exc=inpAcc[i-1])   \n",
    "    \n",
    "    tf = timeit.time()\n",
    "    runTime[j] = tf-t0\n",
    "\n",
    "    ## Print Results Summary ##\n",
    "    print('\\nIteration %d' %(j))\n",
    "    print('Computation Time = %.2f seconds' %((tf-t0)))\n",
    "    print('Mode of Final Parameter Distributions = \\n\\txi = %.4f\\n\\twn = %.4f'\n",
    "          %(modeHist[j,2,-1],modeHist[j,3,-1]))\n",
    "\n",
    "np.savez(outFile, muHist = muHist,stdHist=stdHist, meanHist=meanHist, \n",
    "         modeHist=modeHist, modStates=modStates, runTime = runTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Capacity of the Inferred Models\n",
    "The goal of this section is to develop a prediction of the response behavior of the system to a secondary event, given the models which have been inferred from the primary excitation. \n",
    "\n",
    "### Load Inference Data\n",
    "This becomes an optional start point in the code. If the data for the UKF has already been generated, it can simply be loaded in for the predictive analysis instead of rerunning the previous block of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = np.load(outFile + '.npz')\n",
    "\n",
    "muHist = outData['muHist']         # inference history of untransformed state/par means\n",
    "stdHist = outData['stdHist']       # inference history of state/par standard deviations\n",
    "meanHist = outData['meanHist']     # inference history of transformed state/par means\n",
    "modeHist = outData['modeHist']     # inference history of transformed state/par modes\n",
    "modStates = outData['modStates']   # states that have been remodeled based on the final modes of the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Secondary Input Excitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predInFile = '../04-Data/Linear/predInp_BLWN'\n",
    "predOutFile = '../04-Data/Linear/predOutUKF'\n",
    "\n",
    "infData = np.load(predInFile + '.npz')\n",
    "\n",
    "dt = infData['dt']                            # time step [sec]\n",
    "time = infData['time']                        # time history [sec]\n",
    "predBase = infData['predInp']                 # observations on input acceleration [m/sec^2]\n",
    "predStatesTrue = infData['predStatesPNoise']  # states (for post-prediction validation) [m,m/sec]\n",
    "predRespTrue = infData['predAccPMNoise']      # observations on response acceleration [m/sec^2]\n",
    "Q = infData['Qfactor']                        # process noise contributions, independent std. dev. per state [m,m/sec]\n",
    "R = infData['Rfactor']                        # measurement noise contribution [m/sec^2]\n",
    "m = infData['m']                              # mass [kg]\n",
    "ics = infData['ics']                          # true initial conditions of the system [m, m/sec]\n",
    "par = infData['par']                          # true parameters of the system [xi (-), wn (rad/sec)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictive Distribution on the States over Secondary Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive Distribution from Inferred Results\n",
      "Case 0\n",
      "Case 1\n",
      "Case 2\n",
      "Case 3\n",
      "Case 4\n",
      "Case 5\n",
      "Case 6\n",
      "Case 7\n",
      "Case 8\n",
      "Case 9\n",
      "Case 10\n",
      "Case 11\n",
      "Case 12\n",
      "Case 13\n",
      "Case 14\n",
      "Case 15\n",
      "Case 16\n",
      "Case 17\n",
      "Case 18\n",
      "Case 19\n",
      "Case 20\n",
      "Case 21\n",
      "Case 22\n",
      "Case 23\n",
      "Case 24\n",
      "Case 25\n",
      "Case 26\n",
      "Case 27\n",
      "Case 28\n",
      "Case 29\n",
      "Case 30\n",
      "Case 31\n",
      "Case 32\n",
      "Case 33\n",
      "Case 34\n",
      "Case 35\n",
      "Case 36\n",
      "Case 37\n",
      "Case 38\n",
      "Case 39\n",
      "Case 40\n",
      "Case 41\n",
      "Case 42\n",
      "Case 43\n",
      "Case 44\n",
      "Case 45\n",
      "Case 46\n",
      "Case 47\n",
      "Case 48\n",
      "Case 49\n",
      "\n",
      "Indices of Unstable Predictive Distributions:\n"
     ]
    }
   ],
   "source": [
    "### Set Constants for Predictive Sampling ###\n",
    "nPriors = muHist.shape[0]    # Number of inference trials [-]\n",
    "nSamps = 500                 # Number of samples on the inference posterior [-]\n",
    "seeds = [8192,3245]          # seeds for random number generator\n",
    "\n",
    "### Generate Storage Over Predicted States ###\n",
    "totalSamps = np.zeros((nSamps*nPriors, nState, len(time)))\n",
    "    # Predicted states based on simulations results for all posterior\n",
    "    # samples from all inference trials\n",
    "meanPred = np.zeros((nPriors, nState, len(time)))\n",
    "    # Mean of the predicted states for each inference trial.\n",
    "stdPred = np.zeros((nPriors,nState, len(time)))\n",
    "    # Standard deviation of the predicted states for each inference trial. \n",
    "\n",
    "### Run Predictive Trials on All Candidate Models ###\n",
    "print('Predictive Distribution from Inferred Results')\n",
    "for j in range(nPriors):\n",
    "    print('Case %d'%(j))\n",
    "    ## Random Samples on the States and Parameters, based on Inferred Posterior ##\n",
    "    np.random.seed(seeds[0]+j)\n",
    "    rSamp = np.random.multivariate_normal(np.zeros(nInf), np.eye(nInf), nSamps)\n",
    "    predSamps = muHist[j,:,-1] + stdHist[j,:,-1]*rSamp\n",
    "\n",
    "    ## Random Samples on the Transition Noise ##\n",
    "    np.random.seed(seeds[1]+j)\n",
    "    noise = Q.reshape(-1,1)*np.random.multivariate_normal(np.zeros(nState), np.eye(nState), \n",
    "                                                          (nSamps, len(time))).transpose((0, 2, 1))\n",
    "\n",
    "    ## Prepare Response Storage ##\n",
    "    predStates = np.zeros((nSamps, nState,len(time)))\n",
    "    predStates[:,:,0] = predSamps[:,:nState]\n",
    "\n",
    "    for i in range(nSamps):\n",
    "        for tt in range(1,len(time)):\n",
    "            predStates[i,:,tt] = fx(np.concatenate((predStates[i,:, tt-1], predSamps[i,nState:])), \n",
    "                                                 dt, exc = predBase[tt-1])[:nState] + noise[i,:,tt-1]\n",
    "    \n",
    "    ## Store Results from Predictive Sample Runs ##\n",
    "    meanPred[j,:,:] = np.mean(predStates, axis = 0)\n",
    "    stdPred[j,:,:] = np.sqrt(np.mean(np.square(predStates), axis=0) - np.square(meanPred[j,:,:])) \n",
    "    totalSamps[j*nSamps:(j+1)*nSamps,:,:] = predStates\n",
    "    \n",
    "### Remove Unstable Results from the Overall Assessment ###\n",
    "# Candidate models can become unstable during inference (due to \n",
    "# computational issues such as singularities in the covariance \n",
    "# matrices) or manifest instability during predictive modeling\n",
    "# due to combinations of the selected parameters which result in\n",
    "# model divergence. Here we extract these cases so that they don't \n",
    "# interfere with the statistics of the main results. \n",
    "stabilityInd = np.ones(nPriors)\n",
    "totalStabilityInd = np.ones(nPriors*nSamps)\n",
    "\n",
    "print('\\nIndices of Unstable Predictive Distributions:')\n",
    "for i in range(nPriors):\n",
    "    if (np.isnan(meanPred[i,0,-1])) or (np.absolute(meanPred[i,0,-1])>100) or (muHist[i,0,-1] == 0):\n",
    "        stabilityInd[i] = 0 \n",
    "        totalStabilityInd[i*nSamps:(i+1)*nSamps] = np.zeros(nSamps)\n",
    "        print(i)\n",
    "\n",
    "stableMeans = meanPred[stabilityInd != 0,:,:]\n",
    "stableStds = stdPred[stabilityInd != 0,:,:]\n",
    "stableSamps = totalSamps[totalStabilityInd != 0,:,:]\n",
    "\n",
    "### Statistics on all Stable Cases ###\n",
    "meanAll = np.mean(stableSamps, axis = 0)\n",
    "stdAll = np.sqrt(np.mean(np.square(stableSamps), axis=0) - np.square(meanAll)) \n",
    "\n",
    "### Save Output ###\n",
    "np.savez(predOutFile, meanPred = meanPred,stdPred=stdPred, \n",
    "         stableMeans=stableMeans, stableStds=stableStds, meanAll=meanAll, stdAll=stdAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
