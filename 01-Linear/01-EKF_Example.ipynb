{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Imports ##\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import time as timeit\n",
    "import datetime\n",
    "import sys,os\n",
    "\n",
    "## Kalman Filter Imports ##\n",
    "from filterpy.kalman import ExtendedKalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Kalman Filter\n",
    "In this file, I develop an extended Kalman filter (EKF) solution to the identification of a single-degree-of-freedom oscillator (SDOF), in which the nonlinear switch state is turned off, essentially producing a linear system. As such, the dynamic equations modeled herein are simplified such that they are only representative of a linear SDOF system. \n",
    "\n",
    "No hyperparameters need be selected for this inference algorithm. Typical hyperparameters in an experimental scenario include the process noise covariance $Q$ and the process noise covariance $R$. These terms are assumed known for this problem. \n",
    "\n",
    "This example runs 50 inference trials using varied prior information on the parameters, simulating different assertions an experimentalist might make in a practical identification scenario. Outputs from this model include:\n",
    "1. The mean and standard deviation of the state and log(parameters) over the inference period. \n",
    "2. The mean of the state and parameters over the inference period. \n",
    "3. The mode of the state and parameters over the inference period. \n",
    "4. The computational model response built from the inferred parameters with respect to the input signal used for inference.\n",
    "5. The runtime for each inference trial. \n",
    "\n",
    "The EKF implementation expressed herein is drawn from the python library FilterPy<sup>1</sup>. Some small modifications were made to adapt the library to this problem, and are shown in detail in the code below. \n",
    "\n",
    "__Developed by__: Alana Lund (Purdue University) \\\n",
    "__Last Updated__: 13 Sept. 2021 \\\n",
    "__License__: AGPL-3.0\n",
    "\n",
    "### References\n",
    "<sup>1</sup> R. Labbe, FilterPy v1.4.5, (2021). [https://github.com/rlabbe/filterpy](https://github.com/rlabbe/filterpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assert File Names\n",
    "inFile = '../04-Data/Linear/inferenceInput'\n",
    "outFile = '../04-Data/Linear/outputEKF'\n",
    "\n",
    "infData = np.load(inFile + '.npz')\n",
    "\n",
    "dt = infData['dt']                 # time step [sec]\n",
    "time = infData['time']             # time history [sec]\n",
    "inpAcc = infData['inpAcc']         # observations on input acceleration [m/sec^2]\n",
    "states = infData['statesPNoise']   # states (for post-inference validation) [m,m/sec]\n",
    "respAcc = infData['accPMNoise']    # observations on response acceleration [m/sec^2]\n",
    "Q = infData['Qfactor']             # process noise contributions, independent std. dev. per state [m,m/sec]\n",
    "R = infData['Rfactor']             # measurement noise contribution [m/sec^2]\n",
    "m = infData['m']                   # mass [kg]\n",
    "ics = infData['ics']               # true initial conditions of the system [m, m/sec]\n",
    "par = infData['par']               # true parameters of the system [xi (-), wn (rad/sec)] \n",
    "\n",
    "### Lay Out Problem Dimensionality ###\n",
    "nInf = 4                     # Number of inferred variables [-]\n",
    "nState = states.shape[0]     # Number of states [-]\n",
    "nPar = nInf - nState         # Number of parameters [-]\n",
    "samps = len(time)            # Number of system measurements [-]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting FilterPy to Our Case\n",
    "FilterPy includes built-in classes that help generalize the operations performed on the transmission and emission models through the EKF algorithm. However, this library assumes that the transition function is either linear or that the state transition can be well captured through the Taylor series expansion on the transition. While the Taylor series would be sufficient in this $\\alpha=0$ case, for consistency among the two aspects of this example, we use the full nonlinear (state+parameters unknown) transition function for the prediction step.  \n",
    "\n",
    "Adjustments to the base class to expand the implementation for a nonlinear transition function are made below. Issues with the assumed system dimensionality are resolved through the careful definition of the transition and observation functions, as shown in the subsequent code segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myExtendedKalmanFilter(ExtendedKalmanFilter):\n",
    "    \"\"\"\n",
    "    Here I redefine a single function called \"predict_x\" in the filterPy class \n",
    "    \"ExtendedKalmanFilter\" to specify the precise nonlinear transition function\n",
    "    that is being used for prediction. Note that even for the linear system \n",
    "    (alpha = 0) the transition function is nonlinear due to the quadratic \n",
    "    interaction of the unknown states and parameters.  \n",
    "    \"\"\"\n",
    "    def predict_x(self, u=0):\n",
    "        \"\"\"\n",
    "        State transition model for a SDOF oscillator with a Bouc-Wen switch \n",
    "        state, given that alpha = 0, and therefore the Bouc-Wen component is \n",
    "        switched off.\n",
    "\n",
    "        states = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)).      \n",
    "        u = input/control value at current time step [m/sec^2]\n",
    "        \n",
    "        Sampling rate is asserted below as there is no option in the \n",
    "        current setup to have them as inputs to the function.\n",
    "        \"\"\"\n",
    "        dt = 1/256 # sampling rate [sec]\n",
    "\n",
    "        state = np.squeeze(self.x.T)\n",
    "        par = np.exp(state[2:]) \n",
    "\n",
    "        x1dot = state[0] + dt*state[1]\n",
    "        x2dot = state[1] + dt*(-u - (2*par[0]*par[1])*state[1] \n",
    "                               - np.square(par[1])*state[0])\n",
    "\n",
    "        self.x = np.concatenate((np.stack((x1dot, x2dot), axis=0)\n",
    "                               , state[2:]), axis=0)[:,None]\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Transition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, dt, exc=None):\n",
    "    \"\"\"\n",
    "    State transition model for a SDOF oscillator with a Bouc-Wen switch \n",
    "    state, given that alpha = 0, and therefore the Bouc-Wen component is \n",
    "    switched off.\n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    dt = sampling rate [sec]\n",
    "    exc = input excitation at current time step [m/sec^2]\n",
    "    \"\"\"\n",
    "    if exc is None:\n",
    "        exc = np.zeros(x[1].shape)\n",
    "      \n",
    "    par = np.exp(x[2:])   \n",
    "    x1dot = x[0] + dt*x[1]\n",
    "    x2dot = x[1] + dt*(-exc - (2*par[0]*par[1])*x[1] - np.square(par[1])*x[0])\n",
    "\n",
    "    return np.concatenate((np.stack((x1dot, x2dot), axis=0)\n",
    "                           , x[2:]), axis=0)\n",
    "\n",
    "def fJacob(x, dt, exc=None):\n",
    "    \"\"\"\n",
    "    Calculates the Jacobian of the state transition function for a SDOF\n",
    "    oscillator with a Bouc-Wen switch state, given that alpha = 0, and\n",
    "    therefore the Bouc-Wen component is switched off. \n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    dt = sampling rate [sec]\n",
    "    exc = input excitation at current time step [m/sec^2]\n",
    "    \"\"\"\n",
    "    x = np.squeeze(x.T)  # Dimensionality matching for FilterPy\n",
    "   \n",
    "    if exc is None:\n",
    "        exc = np.zeros(x[1].shape)\n",
    "        \n",
    "    ## Derivatives with Respect to Transition on State x1 ##\n",
    "    d1x0 = - np.square(np.exp(x[3])) \n",
    "    d1x1 = -(2*np.exp(x[2])*np.exp(x[3]))\n",
    "    d1p0 = -(2*np.exp(x[2])*np.exp(x[3]))*x[1]\n",
    "    d1p1 = -(2*np.exp(x[2])*np.exp(x[3]))*x[1] - 2*np.square(np.exp(x[3]))*x[0]\n",
    "       \n",
    "    ## Build State Transition Jacobian ##\n",
    "    F = np.array([[0,1,0,0],\n",
    "                 [d1x0, d1x1, d1p0, d1p1],\n",
    "                 [0,0,0,0],\n",
    "                 [0,0,0,0]])\n",
    "    \n",
    "    Phi = np.eye(4) + dt*F\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Observation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hx(x):\n",
    "    \"\"\"\n",
    "    Measurement model for a SDOF oscillator with a Bouc-Wen switch \n",
    "    state, given that alpha = 0, and therefore the Bouc-Wen component is \n",
    "    switched off.\n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    \"\"\"  \n",
    "    x = np.squeeze(x.T) # Dimensionality matching for FilterPy\n",
    "    \n",
    "    par = np.exp(x[2:])\n",
    "    resp = -(2*par[0]*par[1])*x[1] - np.square(par[1])*x[0]\n",
    "    \n",
    "    return np.eye(1)*resp # Dimensionality matching for FilterPy   \n",
    "\n",
    "### Define Function to Compute Jacobian of Measurement Function ###\n",
    "def hJacob(x):\n",
    "    \"\"\"\n",
    "    Calculates the Jacobian of the measurement function for a SDOF\n",
    "    oscillator with a Bouc-Wen switch state, given that alpha = 0, and\n",
    "    therefore the Bouc-Wen component is switched off. \n",
    "      \n",
    "    x = 1x4 vector of states (disp [m], vel [m/sec]) and parameters \n",
    "                to be inferred (log(xi),log(wn)). \n",
    "    \"\"\"\n",
    "    x = np.squeeze(x.T) # Dimensionality matching for FilterPy\n",
    "    \n",
    "    ## Derivatives with Respect to Transition on State x1 ##\n",
    "    d1x0 = - np.square(np.exp(x[3])) \n",
    "    d1x1 = -(2*np.exp(x[2])*np.exp(x[3]))\n",
    "    d1p0 = -(2*np.exp(x[2])*np.exp(x[3]))*x[1]\n",
    "    d1p1 = -(2*np.exp(x[2])*np.exp(x[3]))*x[1] - 2*np.square(np.exp(x[3]))*x[0]\n",
    "    \n",
    "    return np.array([[d1x0,d1x1,d1p0,d1p1]]) # Dimensionality matching for FilterPy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Extended Kalman Filter\n",
    "As previously noted, we are running inference trials over 50 prior distributions on the parameters to evaluate the variability in the quality of the inferred models over reasonable variations on the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0891\n",
      "\twn = 3.0101\n",
      "\n",
      "Iteration 1\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0843\n",
      "\twn = 3.0067\n",
      "\n",
      "Iteration 2\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0735\n",
      "\twn = 3.0007\n",
      "\n",
      "Iteration 3\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0520\n",
      "\twn = 2.9935\n",
      "\n",
      "Iteration 4\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0495\n",
      "\twn = 2.9928\n",
      "\n",
      "Iteration 5\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0877\n",
      "\twn = 3.0091\n",
      "\n",
      "Iteration 6\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0518\n",
      "\twn = 2.9934\n",
      "\n",
      "Iteration 7\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0720\n",
      "\twn = 3.0003\n",
      "\n",
      "Iteration 8\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0827\n",
      "\twn = 3.0050\n",
      "\n",
      "Iteration 9\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0496\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 10\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0849\n",
      "\twn = 3.0066\n",
      "\n",
      "Iteration 11\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0805\n",
      "\twn = 3.0032\n",
      "\n",
      "Iteration 12\n",
      "Computation Time = 0.36 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0551\n",
      "\twn = 2.9944\n",
      "\n",
      "Iteration 13\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0517\n",
      "\twn = 2.9926\n",
      "\n",
      "Iteration 14\n",
      "Computation Time = 0.36 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0505\n",
      "\twn = 2.9923\n",
      "\n",
      "Iteration 15\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0567\n",
      "\twn = 2.9949\n",
      "\n",
      "Iteration 16\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0515\n",
      "\twn = 2.9933\n",
      "\n",
      "Iteration 17\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0651\n",
      "\twn = 2.9972\n",
      "\n",
      "Iteration 18\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0507\n",
      "\twn = 2.9934\n",
      "\n",
      "Iteration 19\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0905\n",
      "\twn = 3.0109\n",
      "\n",
      "Iteration 20\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0846\n",
      "\twn = 3.0059\n",
      "\n",
      "Iteration 21\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0783\n",
      "\twn = 3.0024\n",
      "\n",
      "Iteration 22\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0563\n",
      "\twn = 2.9948\n",
      "\n",
      "Iteration 23\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0800\n",
      "\twn = 3.0035\n",
      "\n",
      "Iteration 24\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0811\n",
      "\twn = 3.0035\n",
      "\n",
      "Iteration 25\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0980\n",
      "\twn = 3.0162\n",
      "\n",
      "Iteration 26\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0498\n",
      "\twn = 2.9929\n",
      "\n",
      "Iteration 27\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0647\n",
      "\twn = 2.9954\n",
      "\n",
      "Iteration 28\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0844\n",
      "\twn = 3.0063\n",
      "\n",
      "Iteration 29\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0793\n",
      "\twn = 3.0034\n",
      "\n",
      "Iteration 30\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0732\n",
      "\twn = 3.0007\n",
      "\n",
      "Iteration 31\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0786\n",
      "\twn = 3.0026\n",
      "\n",
      "Iteration 32\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0796\n",
      "\twn = 3.0035\n",
      "\n",
      "Iteration 33\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0670\n",
      "\twn = 2.9965\n",
      "\n",
      "Iteration 34\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0526\n",
      "\twn = 2.9936\n",
      "\n",
      "Iteration 35\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0829\n",
      "\twn = 3.0059\n",
      "\n",
      "Iteration 36\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0768\n",
      "\twn = 3.0017\n",
      "\n",
      "Iteration 37\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0504\n",
      "\twn = 2.9931\n",
      "\n",
      "Iteration 38\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0780\n",
      "\twn = 3.0026\n",
      "\n",
      "Iteration 39\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0903\n",
      "\twn = 3.0106\n",
      "\n",
      "Iteration 40\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0496\n",
      "\twn = 2.9929\n",
      "\n",
      "Iteration 41\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0559\n",
      "\twn = 2.9947\n",
      "\n",
      "Iteration 42\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0632\n",
      "\twn = 2.9973\n",
      "\n",
      "Iteration 43\n",
      "Computation Time = 0.36 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0667\n",
      "\twn = 2.9970\n",
      "\n",
      "Iteration 44\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0511\n",
      "\twn = 2.9931\n",
      "\n",
      "Iteration 45\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0532\n",
      "\twn = 2.9933\n",
      "\n",
      "Iteration 46\n",
      "Computation Time = 0.37 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0722\n",
      "\twn = 3.0002\n",
      "\n",
      "Iteration 47\n",
      "Computation Time = 0.39 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0506\n",
      "\twn = 2.9932\n",
      "\n",
      "Iteration 48\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0786\n",
      "\twn = 3.0025\n",
      "\n",
      "Iteration 49\n",
      "Computation Time = 0.38 seconds\n",
      "Mode of Final Parameter Distributions = \n",
      "\txi = 0.0870\n",
      "\twn = 3.0087\n"
     ]
    }
   ],
   "source": [
    "### Load Prior Distributions on the Parameters ###\n",
    "parPriors = np.loadtxt('../04-Data/parameter_priors.txt')\n",
    "\n",
    "### Generate Storage Over Inferred States/Parameters ###\n",
    "muHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mean of the inferred parameters for each inference trial\n",
    "    # over the observation period. This is what the EKF directly\n",
    "    # outputs\n",
    "stdHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # standard deviation of the inferred parameters for each \n",
    "    # inference trial over the observation period. This is \n",
    "    # what the EKF directly outputs\n",
    "meanHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mean of the inferred states and the underlying parameters\n",
    "    # for each inference trial over the observation period. This\n",
    "    # measure transforms the parameters to a lognormal distribution\n",
    "    # such that the statistics on the true parameter values can be\n",
    "    # extracted. \n",
    "modeHist = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # mode of the inferred states and the underlying parameters\n",
    "    # for each inference trial over the observation period. This\n",
    "    # measure transforms the parameters to a lognormal distribution\n",
    "    # such that the statistics on the true parameter values can be\n",
    "    # extracted. \n",
    "modStates = np.zeros((parPriors.shape[0],nInf, samps))\n",
    "    # Response history of the inferred system given the input\n",
    "    # excitation. Essentially, we're remodeling the behavior of \n",
    "    # the system given our selections on point estimates of the \n",
    "    # parameters from the posterior. \n",
    "runTime = np.zeros((parPriors.shape[0]))\n",
    "    # Computational time for each inference trial. \n",
    "\n",
    "## For Each Inference Trial... ##\n",
    "for j in range(parPriors.shape[0]):\n",
    "    ### Create an Instance of the EKF Class ##\n",
    "    kf = myExtendedKalmanFilter(dim_x=nInf, dim_z=1, dim_u=1)\n",
    "        # Initialize UKF solver class with 4 states (2 dynamic, 2 parameter, 1 input)\n",
    "    \n",
    "    ### Initialize EKF Priors ###\n",
    "    mu0 = np.concatenate((10**(-10)*np.ones((nState,)), parPriors[j,:4:2]))[:,None]\n",
    "        # We start the states at not exactly 0 to avoid computational difficulties                                \n",
    "    P0 = np.diag(np.square(np.concatenate((np.array([0.05, 0.05])\n",
    "                                 ,parPriors[j,1:5:2]))))\n",
    "      \n",
    "    kf.x = mu0    # Prior mean on the states and parameters\n",
    "    kf.P = P0     # Prior covariance on the states and parameters\n",
    "    kf.Q = np.diag(np.concatenate((np.square(Q), 10**(-8)*np.ones(nPar)))) \n",
    "        # Adding a little jitter on the parameter transition density is\n",
    "        # standard practice in the joint state-parameter estimation problem. \n",
    "        # Doing so avoids singularity in the covariance on the transition dynamics\n",
    "    kf.R = np.eye(1)*R**2 # Dimensionality matching for FilterPy  \n",
    "\n",
    "    ## Store Initial Values ##\n",
    "    muHist[j,:,0] = np.squeeze(kf.x.T) \n",
    "    stdHist[j,:,0] = np.sqrt(np.diag(kf.P))\n",
    "    meanHist[j,:,0] = np.concatenate((np.squeeze(kf.x.T)[0:nState], \n",
    "                                      np.exp(np.squeeze(kf.x.T)[nState:] \n",
    "                                        + np.square(stdHist[j,nState:,0])/2)))\n",
    "    modeHist[j,:,0] = np.concatenate((np.squeeze(kf.x.T)[0:nState], \n",
    "                                      np.exp(np.squeeze(kf.x.T)[nState:] \n",
    "                                        - np.square(stdHist[j,nState:,0]))))\n",
    "\n",
    "    ### Run EKF Over Data ###\n",
    "    t0 = timeit.time()\n",
    "    try: \n",
    "        for i in range(1,samps):\n",
    "            ## Predictor ##\n",
    "            kf.F = fJacob(kf.x, dt, exc=inpAcc[i-1])\n",
    "            kf.predict(u=inpAcc[i-1])\n",
    "            ## Corrector ##\n",
    "            kf.update(respAcc[i], hJacob, hx)\n",
    "\n",
    "            ## Store Results ##\n",
    "            muHist[j,:,i] = np.squeeze(kf.x.T) \n",
    "            stdHist[j,:,i] = np.sqrt(np.diag(kf.P))\n",
    "            meanHist[j,:,i] = np.concatenate((np.squeeze(kf.x.T)[0:nState], \n",
    "                                             np.exp(np.squeeze(kf.x.T)[nState:] \n",
    "                                           + np.square(stdHist[j,nState:,i])/2)))\n",
    "            modeHist[j,:,i] = np.concatenate((np.squeeze(kf.x.T)[0:nState], \n",
    "                                              np.exp(np.squeeze(kf.x.T)[nState:] \n",
    "                                            - np.square(stdHist[j,nState:,i]))))\n",
    "    except:\n",
    "        print('\\nERROR: Numerical Instability')\n",
    "        ## Store Results ##\n",
    "        for i in range(1,samps):\n",
    "            muHist[j,:,i] = np.array([0,0, -0.1054, 2.3])\n",
    "            stdHist[j,:,i] = 0.01*np.ones(4)\n",
    "            meanHist[j,:,i] = np.concatenate((muHist[j,:nState,i], \n",
    "                                    np.exp(muHist[j,nState:,i] + np.square(stdHist[j,nState:,i])/2)))\n",
    "            modeHist[j,:,i] = np.concatenate((muHist[j,:nState,i], np.exp(muHist[j,nState:,i] \n",
    "                                    - np.square(stdHist[j,nState:,i]))))\n",
    "                                    \n",
    "        \n",
    "    ### Rerun Model with Point Estimates (Mode) of Inferred Parameters ###\n",
    "    modStates[j,:,0] = np.concatenate((np.zeros((2,)), np.log(modeHist[j,2:,-1])))\n",
    "    for i in range(1,samps):\n",
    "        modStates[j,:,i] = fx(modStates[j,:,i-1], dt, exc=inpAcc[i-1])   \n",
    "\n",
    "    tf = timeit.time()\n",
    "    runTime[j] = tf-t0\n",
    "\n",
    "    ### Print Results Summary ###\n",
    "    print('\\nIteration %d' %(j) )\n",
    "    print('Computation Time = %.2f seconds' %((tf-t0)))\n",
    "    print('Mode of Final Parameter Distributions = \\n\\txi = %.4f\\n\\twn = %.4f'\n",
    "          %(modeHist[j,2,-1],modeHist[j,3,-1]))\n",
    "\n",
    "### Save Output ###\n",
    "np.savez(outFile, muHist = muHist,stdHist=stdHist, meanHist=meanHist, \n",
    "         modeHist=modeHist, modStates=modStates, runTime = runTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Capacity of the Inferred Models\n",
    "The goal of this section is to develop a prediction of the response behavior of the system to a secondary event, given the models which have been inferred from the primary excitation. \n",
    "\n",
    "### Load Inference Data\n",
    "This becomes an optional start point in the code. If the data for the EKF has already been generated, it can simply be loaded in for the predictive analysis instead of rerunning the previous code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = np.load(outFile + '.npz')\n",
    "\n",
    "muHist = outData['muHist']         # inference history of untransformed state/par means\n",
    "stdHist = outData['stdHist']       # inference history of state/par standard deviations\n",
    "meanHist = outData['meanHist']     # inference history of transformed state/par means\n",
    "modeHist = outData['modeHist']     # inference history of transformed state/par modes\n",
    "modStates = outData['modStates']   # states that have been remodeled based on the final modes of the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Secondary Input Excitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predInFile = '../04-Data/Linear/predInp_BLWN'\n",
    "predOutFile = '../04-Data/Linear/predOutEKF'\n",
    "\n",
    "infData = np.load(predInFile + '.npz')\n",
    "\n",
    "dt = infData['dt']                            # time step [sec]\n",
    "time = infData['time']                        # time history [sec]\n",
    "predBase = infData['predInp']                 # observations on input acceleration [m/sec^2]\n",
    "predStatesTrue = infData['predStatesPNoise']  # states (for post-prediction validation) [m,m/sec]\n",
    "predRespTrue = infData['predAccPMNoise']      # observations on response acceleration [m/sec^2]\n",
    "Q = infData['Qfactor']                        # process noise contributions, independent std. dev. per state [m,m/sec]\n",
    "R = infData['Rfactor']                        # measurement noise contribution [m/sec^2]\n",
    "m = infData['m']                              # mass [kg]\n",
    "ics = infData['ics']                          # true initial conditions of the system [m, m/sec]\n",
    "par = infData['par']                          # true parameters of the system [xi (-), wn (rad/sec)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictive Distribution on the States over Secondary Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive Distribution from Inferred Models:\n",
      "Case 0\n",
      "Case 1\n",
      "Case 2\n",
      "Case 3\n",
      "Case 4\n",
      "Case 5\n",
      "Case 6\n",
      "Case 7\n",
      "Case 8\n",
      "Case 9\n",
      "Case 10\n",
      "Case 11\n",
      "Case 12\n",
      "Case 13\n",
      "Case 14\n",
      "Case 15\n",
      "Case 16\n",
      "Case 17\n",
      "Case 18\n",
      "Case 19\n",
      "Case 20\n",
      "Case 21\n",
      "Case 22\n",
      "Case 23\n",
      "Case 24\n",
      "Case 25\n",
      "Case 26\n",
      "Case 27\n",
      "Case 28\n",
      "Case 29\n",
      "Case 30\n",
      "Case 31\n",
      "Case 32\n",
      "Case 33\n",
      "Case 34\n",
      "Case 35\n",
      "Case 36\n",
      "Case 37\n",
      "Case 38\n",
      "Case 39\n",
      "Case 40\n",
      "Case 41\n",
      "Case 42\n",
      "Case 43\n",
      "Case 44\n",
      "Case 45\n",
      "Case 46\n",
      "Case 47\n",
      "Case 48\n",
      "Case 49\n",
      "\n",
      "Indices of Unstable Predictive Distributions:\n"
     ]
    }
   ],
   "source": [
    "### Set Constants for Predictive Sampling ###\n",
    "nPriors = muHist.shape[0]    # Number of inference trials [-]\n",
    "nSamps = 500                 # Number of samples on the inference posterior [-]\n",
    "seeds = [8192,3245]          # seeds for random number generator\n",
    "\n",
    "### Generate Storage Over Predicted States ###\n",
    "totalSamps = np.zeros((nSamps*nPriors, nState, len(time)))\n",
    "    # Predicted states based on simulations results for all posterior\n",
    "    # samples from all inference trials\n",
    "meanPred = np.zeros((nPriors, nState, len(time)))\n",
    "    # Mean of the predicted states for each inference trial.\n",
    "stdPred = np.zeros((nPriors,nState, len(time)))\n",
    "    # Standard deviation of the predicted states for each inference trial. \n",
    "\n",
    "### Run Predictive Trials on All Candidate Models ###\n",
    "print('Predictive Distribution from Inferred Models:')\n",
    "for j in range(nPriors):\n",
    "    print('Case %d'%(j))\n",
    "    ## Random Samples on the States and Parameters, based on Inferred Posterior ##\n",
    "    np.random.seed(seeds[0]+j)\n",
    "    rSamp = np.random.multivariate_normal(np.zeros(nInf), np.eye(nInf), nSamps)\n",
    "    predSamps = muHist[j,:,-1] + stdHist[j,:,-1]*rSamp\n",
    "\n",
    "    ## Random Samples on the Transition Noise ##\n",
    "    np.random.seed(seeds[1]+j)\n",
    "    noise = Q.reshape(-1,1)*np.random.multivariate_normal(np.zeros(nState), np.eye(nState), \n",
    "                                                          (nSamps, len(time))).transpose((0, 2, 1))\n",
    "\n",
    "    ## Prepare Response Storage ##\n",
    "    predStates = np.zeros((nSamps, nState,len(time)))\n",
    "    predStates[:,:,0] = predSamps[:,:nState]\n",
    "\n",
    "    for i in range(nSamps):\n",
    "        for tt in range(1,len(time)):\n",
    "            predStates[i,:,tt] = fx(np.concatenate((predStates[i,:, tt-1], predSamps[i,nState:])), \n",
    "                                                 dt, exc = predBase[tt-1])[:nState] + noise[i,:,tt-1]\n",
    "       \n",
    "    ## Store Results from Predictive Sample Runs ##\n",
    "    meanPred[j,:,:] = np.mean(predStates, axis = 0)\n",
    "    stdPred[j,:,:] = np.sqrt(np.mean(np.square(predStates), axis=0) - np.square(meanPred[j,:,:])) \n",
    "    totalSamps[j*nSamps:(j+1)*nSamps,:,:] = predStates\n",
    "    \n",
    "### Remove Unstable Results from the Overall Assessment ###\n",
    "# Candidate models can become unstable during inference (due to \n",
    "# computational issues such as singularities in the covariance \n",
    "# matrices) or manifest instability during predictive modeling\n",
    "# due to combinations of the selected parameters which result in\n",
    "# model divergence. Here we extract these cases so that they don't \n",
    "# interfere with the statistics of the main results. \n",
    "\n",
    "stabilityInd = np.ones(nPriors)\n",
    "totalStabilityInd = np.ones(nPriors*nSamps)\n",
    "\n",
    "print('\\nIndices of Unstable Predictive Distributions:')\n",
    "for i in range(nPriors):\n",
    "    if (np.isnan(meanPred[i,0,-1])) or (np.absolute(meanPred[i,0,-1])>100) or (muHist[i,0,-1] == 0):\n",
    "        stabilityInd[i] = 0 \n",
    "        totalStabilityInd[i*nSamps:(i+1)*nSamps] = np.zeros(nSamps)\n",
    "        print(i)\n",
    "\n",
    "stableMeans = meanPred[stabilityInd != 0,:,:]\n",
    "stableStds = stdPred[stabilityInd != 0,:,:]\n",
    "stableSamps = totalSamps[totalStabilityInd != 0,:,:]\n",
    "\n",
    "### Statistics on all Stable Cases ###\n",
    "meanAll = np.mean(stableSamps, axis = 0)\n",
    "stdAll = np.sqrt(np.mean(np.square(stableSamps), axis=0) - np.square(meanAll)) \n",
    "\n",
    "### Save Output ###\n",
    "np.savez(predOutFile, meanPred = meanPred,stdPred=stdPred, \n",
    "         stableMeans=stableMeans, stableStds=stableStds, meanAll=meanAll, stdAll=stdAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
